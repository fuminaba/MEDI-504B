
---

---
# Data Exploratory Analysis
MEDI-504B Team 2

## Dataset Metadata 
| Variable Name | Column # | Role | Type | Description |   
| --- | --- | --- | --- | --- |   
| quality | 0 | Feature | Binary | 0 = bad quality, 1 = sufficient quality |  
| pre_screening | 1 | Feature | Binary | The binary result of pre-screening, where 1 indicates severe retinal abnormality and 0 its lack.|  
| ma1-6 | 2 - 7 | Feature | Integer | ma1 - ma-6 contain the results of MA detection. Each feature value stand for the number of microaneurysms (MAs) found at the confidence levels alpha = 0.5, . . . , 1, respectively. |  
| exudate1-8 | 8 - 15 | Feature | Continuous | exudate1 - exudate8 contain the same information as 2-7) for exudates. However, as exudates are represented by a set of points rather than the number of pixels constructing the lesions, these features are normalized by dividing the number of lesions with the diameter of the ROI to compensate different image sizes. |  
| macula_opticdisc_distance | 16 | Feature | Continuous | The euclidean distance of the center of the macula and the center of the optic disc to provide important information regarding the patient's condition. This feature is also normalized with the diameter of the ROI.|  
| opticdisc_diameter | 17 | Feature | Continous | The diameter of the optic disc |  
| am_fm_classification | 18 | Feature | Continous | The diameter of the optic disc |  
| Class | 19 | Target | Binary | Class label, 1 = signs of DR, 0 = no sign of DR | 

## Data Preparation

```{r, echo=FALSE, message=FALSE}
library(tidyverse) # for tidy data analysis
library(readr)     # for fast reading of input files
library(here)
```

```{r, echo=FALSE}
diabetic_data0 <- 
    here("Datasets", "diabetic_retinopathyDataSet_train.csv") %>% 
    read.csv(header = TRUE, stringsAsFactors = F)

names(diabetic_data0) <-  
    c("quality", "pre_screening", 
      "ma1", "ma2", "ma3", "ma4", "ma5", "ma6", 
      "exudate1", "exudate2", "exudate3", "exudate4",
      "exudate5", "exudate6", "exudate7","exudate8",
      "macula_opticdisc_distance", "opticdisc_diameter",
      "am_fm_classification", "classes")

diabetic_data1 <- diabetic_data0 %>%
  dplyr::mutate(classes = ifelse(classes == 0, "No",
                          ifelse(classes == 1, "Sign", NA)))

# Missing Data---
# use only complete cases
# Missing values can be imputed we will see this later-- for now we will remove!
diabetic_data2 <- diabetic_data1[complete.cases(diabetic_data1),] %>% 
    filter(quality == 1) %>% 
    select(-quality)

# Split into predictor data and class data
diabetic_pred <- diabetic_data2 %>% select(-classes)
diabetic_class <- diabetic_data2$classes
```

We can print the summary of data.
```{r}
# Exploratory Data Analysis----
summary(diabetic_data1) # Basic 
```

## Data Exploratary Analysis
We can also try to use the library `DataExplorer` to automated EDA.
From the auto-generated report, we can conclude that

*  There is no missing observation.
*  From boxplots and histograms, the distribution of the `ma*` variables have same distribution and highly correlated. So are the `exudate*` variables.
*  From QQ-plot, Only the variables `macula_opticdisc_distance` and `opticdisc_diameter` have approximate normal distribution. Other variables are very far from normal distribution.

```{r, echo=FALSE}
library(DataExplorer)
##run the following line to see the auto-generated EDA
#invisible(create_report(diabetic_data1)) 
```
The bar plot of two classes is drawn. Notice that we have more "Sign" than "No"-- there is a slight class imbalance.
```{r, echo=FALSE}
ggplot(diabetic_data2, aes(x = classes, fill = classes)) + geom_bar()
```

```{r}
# Calculate the proportion of data belonging to each class
class.sign.prop <- 
    nrow(diabetic_data2[diabetic_data2$classes=='Sign',]) / nrow(diabetic_data2)
class.no.prop <- 
    nrow(diabetic_data2[diabetic_data2$classes=='No',]) / nrow(diabetic_data2)

print(paste(
    "Proportion of class 'Sign':", 
    class.sign.prop, 
    "Proportion of 'No':", 
    class.no.prop))
```
However, the split seems fairly even, thus it may not be necessary to make class imbalance changes when training predictive models. 

The boxplots below show that most of continous random variables have heavy-tail(right-skew) distribution.
```{r, echo=FALSE}
options(repr.plot.width = 10,repr.plot.height = 2.5) #repr.plot.res = 100)
feature.vals.boxplot <- 
    ggplot(stack(diabetic_pred), aes(x = ind, y = values)) + 
    geom_boxplot() + 
    labs(
        title = "Boxplots of feature values",
        x = "Feature Names",
        y = "Values") + 
    scale_y_continuous(breaks = seq(0, 1000, by = 20)) +
    theme(
        axis.text.x = element_text(angle = 60, hjust = 1, vjust=1),
        legend.position = "none",
        axis.title = element_text(size = 12),
        panel.grid = element_blank()
    )

feature.vals.boxplot +
    geom_jitter(size = 1, alpha = 0.25, width = 0.2) +
    stat_summary(fun = mean, geom = "point", size = 2, color = 'yellow') 
```

```{r}
# Create correlation matrices
# For patients with no sign of diabetic retinopathy
corr.matrix.no.DR <- filter(diabetic_data2, classes == "No") %>%
  select(-classes) %>%
  cor()
# For patients with signs of diabetic retinopathy
corr.matrix.signs.DR <- filter(diabetic_data2, classes == "Sign") %>%
  select(-classes) %>%
  cor()
```

Principal Component Analysis
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ellipse)
```
perform pca and extract scores
```{r}
pcaOutput <- prcomp(as.matrix(select(diabetic_data2, -classes)), scale = TRUE, center = TRUE)
pcaOutput2 <- as.data.frame(pcaOutput$x)
PoV <- pcaOutput$sdev^2/sum(pcaOutput$sdev^2)
PoV
# define groups for plotting
pcaOutput2$groups <- diabetic_data2$classes
centroids <- aggregate(cbind(PC1, PC2) ~ groups, pcaOutput2, mean)
conf.rgn  <- do.call(rbind, lapply(unique(pcaOutput2$groups), function(t)
  data.frame(groups = as.character(t),
             ellipse(cov(pcaOutput2[pcaOutput2$groups == t, 1:2]),
                     centre = as.matrix(centroids[centroids$groups == t, 2:3]),
                     level = 0.95),
             stringsAsFactors = FALSE)))
```
```{r, fig.height=6, fig.width=10}
g1 <- ggplot(data = pcaOutput2, aes(x = PC1, y = PC2, group = groups, color = groups)) + 
  geom_polygon(data = conf.rgn, aes(fill = groups), alpha = 0.2) +
  geom_point(size = 2, alpha = 0.6) + 
  labs(color = "",
       fill = "") 
# Can also make output more informative
g2 <- g1+
  labs(x = paste0("PC1: ", round(PoV[1], digits = 2) * 100, "% variance"),
       y = paste0("PC2: ", round(PoV[2], digits = 2) * 100, "% variance"))
g2
```
Basic summary stats
```{r}
psych::describeBy(diabetic_data2)
psych::describeBy(diabetic_pred, diabetic_class)
# a better looking table
arsenal::tableby(classes~., data = diabetic_data2, total= TRUE) %>% summary(text = TRUE)
```


## User Stories 
| User | Stories | Refined Stories | Extracted Tasks | 
| :--- | :--- | :--- | :--- | 
| Patients | I would like a quick and accurate diagnosis tool so I don’t have to undergo unnecessary exams and procedures, or get misdiagnosed for something I don’t have and have eye surgery. | I would like a predictive model that is at least 95% sensitive and specific, (AUC as high as possible) with an emphasis on sensitivity so possibility of retinopathy is not missed. | TBD | 
| Family Members | I would like a predictive model with minimal false negatives and false positives to screen for diabetic retinopathy, so I can make informed clinical decisions.| I would want a predictive model that has the highest specificity, at least 90%, so my family member does not need to undergo unnecessary treatment and stress. | TBD |  
| Primary Physician | I would like a predictive model with minimal false negatives and false positives to screen for diabetic retinopathy, so I can make informed clinical decisions. | I would like a predictive model with high AUC validated on external data so I can make informed clinical decisions with confidence | TBD | 
| Ophthalmologist | I would like an accurate, easy-to-use and interpretable model to help me detect diabetic retinopathy when clients come in for exams. | This model should have high sensitivity so I can refer them to the required further tests to investigate the probability of retinopathy | TBD | 
| Insurance company | I want to have an accurate prediction model on if clients are likely to get diabetic retinopathy so that I can make the insurance plan more profitable based on people’s health conditions. | The model should have very high sensitivity, over 95% so we can incorporate any probability of patients developing retinopathy into the insurance plan. It is okay to have high false negatives, since that will be more beneficial for the company. | TBD | 
| Public Heath Researchers | I would like a model to gather data on the likelihood of diabetic retinopathy in certain populations to make informative communication and decisions with the public. |  | TBD | 
 



