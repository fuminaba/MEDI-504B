# Read clean data
library(readr)     # for fast reading of input files
library(here)
library(bestglm)
library(caret)
library(pROC)
library(dplyr)
library(tidyverse) # for tidy data analysis

source(here("Workspace", "Sprint-1_logistic-Regression", "util_funcs.R"))

# >>> Load the dataset <<< #
diabetic_data0 <- 
  here("Datasets", "diabetic_retinopathyDataSet_train.csv") %>% 
  read.csv(header = TRUE, stringsAsFactors = F)

# >>> Assign feature names <<< #
names(diabetic_data0) <-  
  c("quality", "pre_screening", 
    "ma1", "ma2", "ma3", "ma4", "ma5", "ma6", 
    "exudate1", "exudate2", "exudate3", "exudate4",
    "exudate5", "exudate6", "exudate7","exudate8",
    "macula_opticdisc_distance", "opticdisc_diameter",
    "am_fm_classification", "classes")

# >>> Recode numeric outcome variable to string, then factor <<< #
diabetic_data1 <- diabetic_data0 %>%
  mutate(classes = ifelse(classes == 0, "No",
                          ifelse(classes == 1, "Sign", NA))) %>%
  mutate(classes = as_factor(classes))


eval_mod <- function(model, data) {
  pred <- predict(model, data)
  cm <- caret::confusionMatrix(pred, data$classes, positive="malignant")
  auc <- roc(data$classes,
             predict(model, data, type = "prob")[, "malignant"]) %>% auc()
  result <- c(cm$overall["Accuracy"],cm$byClass['Sensitivity'], cm$byClass['Specificity'], cm$byClass['F1'],AUC=auc)
  return(result)
}




diabetic_data1$classes <- as.factor(diabetic_data1$classes)

set.seed(2024)
index <- caret::createDataPartition(diabetic_data1$classes, p = 0.7, list = FALSE)

train_data <- diabetic_data1[index, ]
test_data  <- diabetic_data1[-index, ]

train_data$classes %>% table(.)
set.seed(2024)

ctrl <- trainControl(method = "repeatedcv", 
                     number = 5, 
                     repeats = 3,  
                     savePredictions = TRUE,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
set.seed(2024)

forest_fit <- train(
  classes ~ .,
  data = train_data,                         
  method = "ranger",
  metric = "ROC",
  trControl = trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary),
  importance="impurity"
)
forest <- eval_mod(forest_fit,test_data)

set.seed(2024)

gbm_fit <- train(classes ~ .,
                 data = train_data,
                 method = "gbm",
                 verbose = FALSE,
                 metric = "Sens",
                 trControl = ctrl)

gbm <- eval_mod(gbm_fit,test_data)

modelLookup("xgbTree")

# nrounds: number of boosting iterations, M
# max_depth: maximum tree depth
# eta: shrinkage,  Î·
# gamma: minimum loss reduction
# colsamle_bytree: subsample ratio of columns
# min_child_weight: minimum size of instance weight
# substample: subsample percentage
# An alternative to tuneGrid
# tuneLength argument is used to control the number of combinations generated by this random tuning parameter search.
# 
# 
set.seed(2024)

xgboostT_fit <- train(classes ~ .,
                      data = train_data,
                      method = "xgbTree",
                      verbose = FALSE,
                      metric = "Sens",
                      trControl = ctrl)


xgboost_tree <- eval_mod(xgboostT_fit,test_data)


set.seed(2024)

xgboostL_fit <- train(classes ~ .,
                      data = train_data,
                      method = "xgbLinear",
                      verbose = FALSE,
                      tuneLength=5,
                      metric = "Sens",
                      trControl = ctrl)

xgboost_linear <- eval_mod(xgboostL_fit,test_data)


rbind(forest, gbm, xgboost_tree, xgboost_linear)


# Variable importance
# 
# Calculate variable importance using vip
# 
varImp(xgboostL_fit)

vip::vip(xgboostL_fit , num_features = 10) 

vip::vip(xgboostT_fit , num_features = 10) 
vip::vip(forest_fit , num_features = 10) 
