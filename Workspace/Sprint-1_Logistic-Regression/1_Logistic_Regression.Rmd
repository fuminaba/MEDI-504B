---
output:
  html_document: default
  pdf_document: default
---


# Logistic Regression - Detecting Signs of Diabetic Retinopathy 
MEDI-504B  

## Dataset Metadata 
| Variable Name | Column # | Role | Type | Description |   
| --- | --- | --- | --- | --- |   
| quality | 0 | Feature | Binary | 0 = bad quality, 1 = sufficient quality |  
| pre_screening | 1 | Feature | Binary | The binary result of pre-screening, where 1 indicates severe retinal abnormality and 0 its lack.|  
| ma1-6 | 2 - 7 | Feature | Integer | ma1 - ma-6 contain the results of MA detection. Each feature value stand for the number of microaneurysms (MAs) found at the confidence levels alpha = 0.05, . . . , 1, respectively. |  
| exudate1-8 | 8 - 15 | Feature | Continuous | exudate1 - exudate8 contain the same information as 2-7) for exudates. However, as exudates are represented by a set of points rather than the number of pixels constructing the lesions, these features are normalized by dividing the number of lesions with the diameter of the ROI to compensate different image sizes. |  
| macula_opticdisc_distance | 16 | Feature | Continuous | The euclidean distance of the center of the macula and the center of the optic disc to provide important information regarding the patient's condition. This feature is also normalized with the diameter of the ROI.|  
| opticdisc_diameter | 17 | Feature | Continous | The diameter of the optic disc |  
| am_fm_classification | 18 | Feature | Continous | The diameter of the optic disc |  
| Class | 19 | Target | Binary | Class label, 1 = signs of DR, 0 = no sign of DR | 

## Dataset Preparation Steps
We will load the required packages first.
```{r echo=FALSE, message=FALSE}
library(tidyverse) # for tidy data analysis
library(readr)     # for fast reading of input files
library(here)
library(bestglm)
library(caret)
library(pROC)

source("./util_funcs.R")
```
The dataset, located under the `Datasets` folder can be found using the `here` package function. 
Because we are interested in predictions, we compute a table that displays how discriminative each feature is of the outcome class in the dataset using the `tableby` function from the `arsenal` package.
```{r}
# >>> Load the dataset <<< #
diabetic_data0 <- 
    here("Datasets", "diabetic_retinopathyDataSet_train.csv") %>% 
    read.csv(header = TRUE, stringsAsFactors = F)

# >>> Assign feature names <<< #
names(diabetic_data0) <-  
    c("quality", "pre_screening", 
      "ma1", "ma2", "ma3", "ma4", "ma5", "ma6", 
      "exudate1", "exudate2", "exudate3", "exudate4",
      "exudate5", "exudate6", "exudate7","exudate8",
      "macula_opticdisc_distance", "opticdisc_diameter",
      "am_fm_classification", "classes")

# >>> Recode numeric outcome variable to string, then factor <<< #
diabetic_data1 <- diabetic_data0 %>%
    mutate(classes = ifelse(classes == 0, "No",
                     ifelse(classes == 1, "Sign", NA))) %>%
    mutate(classes = as_factor(classes))

# >>> Generate Table of Feature Summary by Class <<< #
arsenal::tableby(classes~., data = diabetic_data1, total= TRUE) %>% 
    summary(text = TRUE)
```

Using a confidence level ($\alpha$) of 0.05, We see that the following features:  
`exudate1`, `exudate2`, `exudate3`, `macula_opticdisc_distance`, `opticdisc_diameter`, `am_fm_classification`  
do not discriminate `Sign` of diabetic retinopathy and `No` sign of diabetic retinopathy very well.
Thus we will remove these features. 

To remove possibility of multicollinearity, we will look at a correlation matrix.
```{r}
correlation_matrix <- diabetic_data1 %>%
    select(-c(classes)) %>%
    cor()

eda.correlation_matrix.plot <- correlation_matrix %>%
    reshape2::melt() %>%
    ggplot(aes(Var1, Var2, fill = value)) +
        geom_tile(color = "white") +
        scale_fill_gradient2(
            low = "darkblue", 
            mid = "white", 
            high = "darkred", 
            midpoint = 0) +
        theme_minimal() +
        labs(
            title = "Feature Correlation Heatmap", 
            x = "Variable 1",
            y = "Variable 2") +
        theme(
            axis.text.x = element_text(angle = 45, hjust = 1))
eda.correlation_matrix.plot
```

We see there is a heavy correlation between the `ma1-6` features and in `exudate1-3` and `exudate5-8`. Thus we will sum the `ma1-6` features (as these features are counts) and average `exudate5-8` features (these are normalized floating point values). `exudate1-3` will be removed as they are not statistically different using a $\alpha$ = 0.05. 

## Data Preprocessing
Utilizing the info from EDA above, we will perform preprocessing on the data before training the logistic regression model. 
The preprocessing steps are summarized in the `data_preproc` function defined in `util_funcs.R`. 
The preprocessing steps are:
1. Filter data for quality == 1 (good quality data)
2. Convert binary features to factors 
3. Combine the `ma1-6` and `exudate5-8` features to avoid multicollinearity 
4. Remove redundant (`ma1-6` and `exudate5-8`) and non-discriminatory (`macula_opticdisc_distance`, `opticdisc_diameter`, `am_fm_classification`) features
The data will not be scaled and centered here - this will be an inherent property of the model. 

We also perform a single holdout train-test split. The 'test' set here will serve as the validation dataset, and the 'train' data will be used to train a logistic regression model using `repeatedcv`.   
We are running a cross-validation to:  
1. Get a good estimate on model performance, and that it's not biased by train-test split
2. Feature selection (ensure feature selection is not biased by train-test split)
```{r}
# Split into predictor data and class data
diabetic_data2A <- diabetic_data1[complete.cases(diabetic_data1),] %>% 
    data_preproc() # >>> Defined in util_funcs.R

diabetic_data2B <- diabetic_data1[complete.cases(diabetic_data1),] %>%
    filter(quality == 1) %>%
    mutate(am_fm_classification = as_factor(am_fm_classification),
           pre_screening = as_factor(pre_screening)) %>%
    select(-quality)

set.seed(178)
sample <- caret::createDataPartition(diabetic_data2A$classes, 
                                     p = 0.7, 
                                     list = FALSE)

trainA  <- diabetic_data2A[sample, ]
testA   <- diabetic_data2A[-sample, ]

trainB <- diabetic_data2B[sample, ]
testB  <- diabetic_data2B[-sample, ]
```

Now that the data is ready, we wil train the logistic regression model. 
We use a generalized logistic regression model here, using `glmStepAIC` to also include feature selection.
Centering and scaling of the data is performed here, and the metric to optimize is Sensitivity, as this is our metric of interest for the User (patient).

```{r}
source("./util_funcs.R")
set.seed(178)
train_method <- trainControl(method = "repeatedcv", 
                             number = 5, 
                             repeats = 5,
                             savePredictions = TRUE,
                             summaryFunction = twoClassSummary,
                             classProbs = TRUE)

diab_ret.glmA <- train(classes ~ .,
                      data = trainA,
                      method = "glmStepAIC", 
                      direction = "both",
                      trControl = train_method,
                      preProc = c("center", "scale"),
                      metric = "Sens",
                      trace = F)

diab_ret.glmA

# see which variables are selected finally
diab_ret.glmA$finalModel

#plot(diab_ret.glmA$finalModel)

trainA %>%
    mutate(exudate_mean = (exudate1)) %>%
    ggplot(aes(x = exudate_mean)) +
    geom_histogram(bins = 100)
```
```{r}

pred <- predict(diab_ret.glmA, testA, type = 'prob') 

testA$logodds <- log(pred$Sign / (1 - pred$Sign))

testA %>%
    mutate(exudate1 = (exudate1)) %>%
           #exudate_mean = cos(exudate_mean)) %>%
    ggplot(aes(x = exudate_mean, y = logodds)) + 
    theme_bw() + 
    theme(
       axis.line = element_blank(),
       panel.grid.major = element_blank(),
       panel.grid.minor = element_blank(),
       panel.background = element_blank()
    ) +
    labs(
        title = 'Log odds vs Mean Exudate Feature',
        x = 'Exudate average', 
        y = 'log odds'
    ) + 
    geom_point()
    
```



```{r}
set.seed(178)
diab_ret.glmB <- train(classes ~ .,
                      data = trainB,
                      method = "glmStepAIC", 
                      direction = "both",
                      trControl = train_method,
                      preProc = c("center", "scale"),
                      metric = "Sens",
                      trace = F)

diab_ret.glmB

# see which variables are selected finally
diab_ret.glmB$finalModel

plot(diab_ret.glmB$finalModel)

```

Following model training, we can evaluate it on the holdout set, view the features that were selected and check the correlation between those features. 

```{r}
# >>> Run an evaluation of the model <<< #
diab_ret.glm.eval <- eval_mod(diab_ret.glmA, testA)

#double check colinearity
# >>> Get names of selected parameters (remove 'Intercept' and factors) <<< #
selected_variables <- names(coef(diab_ret.glmA$finalModel))[c(-1,-2)]

# >>> Create correlation matrix <<<# 
correlation_matrix <- diabetic_data2A %>%
    select(all_of(selected_variables)) %>%
    cor()

correlation_matrix.plot <- correlation_matrix %>%
    reshape2::melt() %>%
    ggplot(aes(Var1, Var2, fill = value)) +
        geom_tile(color = "white") +
        scale_fill_gradient2(
            low = "darkblue", 
            mid = "white", 
            high = "darkred", 
            midpoint = 0
        ) +
        theme_minimal() +
        labs(
            title = "Correlation Heatmap", 
            x = "Axis 1", 
            y = "Axis 2"
        ) +
        theme(
            axis.text.x = element_text(angle = 45, hjust = 1)
        )

# >>> Display the results <<< #
diab_ret.glm.eval
correlation_matrix.plot
```

Our final result is a model with sensitivity ~66%. We do not seem to have multicollinearity effects. 

## Regularization
We can try to add regularization to see which features are favored. 

```{r}
train_method <- trainControl(method = "repeatedcv", 
                             number = 5, 
                             repeats = 5,
                             savePredictions = TRUE,
                             summaryFunction = twoClassSummary,
                             classProbs = TRUE)

lambda <- 10^seq(-4, 0, length = 20)
alpha <- seq(0, 0.5, length = 6)

set.seed(178)
diab_ret.glm.lassoA <- train(classes ~ .,
                             data = trainA,
                             method = "glmnet", 
                             direction = "both",
                             trControl = train_method,
                             tuneGrid = expand.grid(alpha = 1, 
                                                    lambda = lambda),
                             preProc = c("center", "scale"),
                             metric = "ROC",
                             trace = F)
lassoA <- eval_mod(diab_ret.glm.lassoA, testA)

set.seed(178)
diab_ret.glm.ridgeA <- train(classes ~ .,
                             data = trainA,
                             method = "glmnet", 
                             direction = "both",
                             trControl = train_method,
                             tuneGrid = expand.grid(alpha = 0, 
                                                    lambda = lambda),
                             preProc = c("center", "scale"),
                             metric = "ROC",
                             trace = F)
ridgeA <- eval_mod(diab_ret.glm.ridgeA, testA)

set.seed(178)
diab_ret.glm.enetA  <- train(classes ~ .,
                             data = trainA,
                             method = "glmnet", 
                             direction = "both",
                             trControl = train_method,
                             tuneGrid = expand.grid(alpha = alpha, 
                                                    lambda = lambda),
                             preProc = c("center", "scale"),
                             metric = "ROC",
                             trace = F)
enetA <- eval_mod(diab_ret.glm.enetA, testA)
```


```{r}
saveRDS(diab_ret.glmA, "./dr_glm.RDS")
saveRDS(diab_ret.glm.lassoA, "./dr_glm_lasso.RDS")
saveRDS(diab_ret.glm.ridgeA, "./dr_glm_ridge.RDS")
saveRDS(diab_ret.glm.enetA, "./dr_glm_enet.RDS")
#diab_ret.glm.enetA$finalModel
```


```{r}
train_method <- trainControl(method = "repeatedcv", 
                             number = 5, 
                             repeats = 5,
                             savePredictions = TRUE,
                             summaryFunction = twoClassSummary,
                             classProbs = TRUE)

lambda <- 10^seq(-4, 0, length = 20)
alpha <- seq(0, 0.5, length = 6)

set.seed(178)
diab_ret.glm.lassoB <- train(classes ~ .,
                             data = trainB,
                             method = "glmnet", 
                             direction = "both",
                             trControl = train_method,
                             tuneGrid = expand.grid(alpha = 1, 
                                                    lambda = lambda),
                             preProc = c("center", "scale"),
                             metric = "ROC",
                             trace = F)
lassoB <- eval_mod(diab_ret.glm.lassoB, testB)

set.seed(178)
diab_ret.glm.ridgeB <- train(classes ~ .,
                             data = trainB,
                             method = "glmnet", 
                             direction = "both",
                             trControl = train_method,
                             tuneGrid = expand.grid(alpha = 0, 
                                                    lambda = lambda),
                             preProc = c("center", "scale"),
                             metric = "ROC",
                             trace = F)
ridgeB <- eval_mod(diab_ret.glm.ridgeB, testB)

set.seed(178)
diab_ret.glm.enetB  <- train(classes ~ .,
                             data = trainB,
                             method = "glmnet", 
                             direction = "both",
                             trControl = train_method,
                             tuneGrid = expand.grid(alpha = alpha, 
                                                    lambda = lambda),
                             preProc = c("center", "scale"),
                             metric = "ROC",
                             trace = F)
enetB <- eval_mod(diab_ret.glm.enetB, testB)
```

```{r}
plot(diab_ret.glm.lassoB$finalModel)

```
